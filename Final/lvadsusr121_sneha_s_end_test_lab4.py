# -*- coding: utf-8 -*-
"""LVADSUSR121_SNEHA_S_END_TEST_LAB4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bGV1EuTZq_A69xjmmGEkoR3lLlvtTX3w
"""

import pandas as pd
df_m = pd.read_csv('/content/drive/MyDrive/Predictive analytics Practice/social_network.csv')

df = df_m.iloc[:225,:]
df_test = df_m.iloc[225:,:]
df.info()

df.isnull().sum()

duplicates = df.duplicated(keep=False)
df['dup_bool'] = duplicates
print(df[df['dup_bool'] == True].count())
df.drop('dup_bool',axis=1,inplace=True)
df.head(1)

from sklearn.ensemble import IsolationForest
import warnings
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt

features = ["login_activity", "posting_activity", "social_connections"]

X = df[features]

model = IsolationForest()

model.fit(X)

y_pred = model.predict(X)
df["anomaly_score"] = model.decision_function(X)

anomalies = df.loc[df["anomaly_score"] < 0]

x=df_test[["login_activity", "posting_activity", "social_connections"]]
df_values=x.values

find=df_values

result=[]
for i in find:
  z=model.predict([i])
  if z==[1]:
    result.append('Not Anomaly')
  elif z==[-1]:
    result.append('Anomaly')

df_test['Anomaly']=result
print(df_test)

plt.scatter(df["social_connections"], df["anomaly_score"], label="Not Anomaly")
plt.scatter(anomalies["social_connections"], anomalies["anomaly_score"], color="r", label="Anomaly")
plt.xlabel("Social Connections")
plt.ylabel("anomaly_score")
plt.legend()
plt.show()

df_test.head()